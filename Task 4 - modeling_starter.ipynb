{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4noH7q4USKQ"
   },
   "source": [
    "# Feature Engineering and Modelling\n",
    "\n",
    "---\n",
    "\n",
    "1. Import packages\n",
    "2. Load data\n",
    "3. Modelling\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NwE6osQpUSKS"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cm3WmjAZUSKT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Shows plots in jupyter notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Set plot style\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sewogUFaUSKU"
   },
   "source": [
    "---\n",
    "## 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oaIJfXJjUSKU",
    "outputId": "c218e74d-f4bb-4150-b1e3-22d38d83fc07"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cons_12m</th>\n",
       "      <th>cons_gas_12m</th>\n",
       "      <th>cons_last_month</th>\n",
       "      <th>forecast_cons_12m</th>\n",
       "      <th>forecast_discount_energy</th>\n",
       "      <th>forecast_meter_rent_12m</th>\n",
       "      <th>forecast_price_energy_off_peak</th>\n",
       "      <th>forecast_price_energy_peak</th>\n",
       "      <th>forecast_price_pow_off_peak</th>\n",
       "      <th>...</th>\n",
       "      <th>months_modif_prod</th>\n",
       "      <th>months_renewal</th>\n",
       "      <th>channel_MISSING</th>\n",
       "      <th>channel_ewpakwlliwisiwduibdlfmalxowmwpci</th>\n",
       "      <th>channel_foosdfpfkusacimwkcsosbicdxkicaua</th>\n",
       "      <th>channel_lmkebamcaaclubfxadlmueccxoimlema</th>\n",
       "      <th>channel_usilxuppasemubllopkaafesmlibmsdf</th>\n",
       "      <th>origin_up_kamkkxfxxuwbdslkwifmmcsiusiuosws</th>\n",
       "      <th>origin_up_ldkssxwpmemidmecebumciepifcamkci</th>\n",
       "      <th>origin_up_lxidpiddsbxsbosboudacockeimpuepw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24011ae4ebbe3035111d65fa7c15bc57</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.739944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444045</td>\n",
       "      <td>0.114481</td>\n",
       "      <td>0.098142</td>\n",
       "      <td>40.606701</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d29c2c54acc38ff3c0614d0a653813dd</td>\n",
       "      <td>3.668479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.280920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.237292</td>\n",
       "      <td>0.145711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.311378</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>764c75f661154dac3a6c254cd082ea7d</td>\n",
       "      <td>2.736397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.689841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.599009</td>\n",
       "      <td>0.165794</td>\n",
       "      <td>0.087899</td>\n",
       "      <td>44.311378</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bba03439a292a1e166f80264c16191cb</td>\n",
       "      <td>3.200029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.382089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.318689</td>\n",
       "      <td>0.146694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.311378</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149d57cf92fc41cf94415803a877cb4b</td>\n",
       "      <td>3.646011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.721811</td>\n",
       "      <td>2.650065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.122969</td>\n",
       "      <td>0.116900</td>\n",
       "      <td>0.100015</td>\n",
       "      <td>40.606701</td>\n",
       "      <td>...</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  cons_12m  cons_gas_12m  cons_last_month  \\\n",
       "0  24011ae4ebbe3035111d65fa7c15bc57  0.000000      4.739944         0.000000   \n",
       "1  d29c2c54acc38ff3c0614d0a653813dd  3.668479      0.000000         0.000000   \n",
       "2  764c75f661154dac3a6c254cd082ea7d  2.736397      0.000000         0.000000   \n",
       "3  bba03439a292a1e166f80264c16191cb  3.200029      0.000000         0.000000   \n",
       "4  149d57cf92fc41cf94415803a877cb4b  3.646011      0.000000         2.721811   \n",
       "\n",
       "   forecast_cons_12m  forecast_discount_energy  forecast_meter_rent_12m  \\\n",
       "0           0.000000                       0.0                 0.444045   \n",
       "1           2.280920                       0.0                 1.237292   \n",
       "2           1.689841                       0.0                 1.599009   \n",
       "3           2.382089                       0.0                 1.318689   \n",
       "4           2.650065                       0.0                 2.122969   \n",
       "\n",
       "   forecast_price_energy_off_peak  forecast_price_energy_peak  \\\n",
       "0                        0.114481                    0.098142   \n",
       "1                        0.145711                    0.000000   \n",
       "2                        0.165794                    0.087899   \n",
       "3                        0.146694                    0.000000   \n",
       "4                        0.116900                    0.100015   \n",
       "\n",
       "   forecast_price_pow_off_peak  ...  months_modif_prod  months_renewal  \\\n",
       "0                    40.606701  ...                  2               6   \n",
       "1                    44.311378  ...                 76               4   \n",
       "2                    44.311378  ...                 68               8   \n",
       "3                    44.311378  ...                 69               9   \n",
       "4                    40.606701  ...                 71               9   \n",
       "\n",
       "   channel_MISSING  channel_ewpakwlliwisiwduibdlfmalxowmwpci  \\\n",
       "0                0                                         0   \n",
       "1                1                                         0   \n",
       "2                0                                         0   \n",
       "3                0                                         0   \n",
       "4                1                                         0   \n",
       "\n",
       "   channel_foosdfpfkusacimwkcsosbicdxkicaua  \\\n",
       "0                                         1   \n",
       "1                                         0   \n",
       "2                                         1   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "\n",
       "   channel_lmkebamcaaclubfxadlmueccxoimlema  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         1   \n",
       "4                                         0   \n",
       "\n",
       "   channel_usilxuppasemubllopkaafesmlibmsdf  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "\n",
       "   origin_up_kamkkxfxxuwbdslkwifmmcsiusiuosws  \\\n",
       "0                                           0   \n",
       "1                                           1   \n",
       "2                                           1   \n",
       "3                                           1   \n",
       "4                                           1   \n",
       "\n",
       "   origin_up_ldkssxwpmemidmecebumciepifcamkci  \\\n",
       "0                                           0   \n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "\n",
       "   origin_up_lxidpiddsbxsbosboudacockeimpuepw  \n",
       "0                                           1  \n",
       "1                                           0  \n",
       "2                                           0  \n",
       "3                                           0  \n",
       "4                                           0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data_for_predictions.csv')\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14606 entries, 0 to 14605\n",
      "Data columns (total 63 columns):\n",
      " #   Column                                      Non-Null Count  Dtype  \n",
      "---  ------                                      --------------  -----  \n",
      " 0   id                                          14606 non-null  object \n",
      " 1   cons_12m                                    14606 non-null  float64\n",
      " 2   cons_gas_12m                                14606 non-null  float64\n",
      " 3   cons_last_month                             14606 non-null  float64\n",
      " 4   forecast_cons_12m                           14606 non-null  float64\n",
      " 5   forecast_discount_energy                    14606 non-null  float64\n",
      " 6   forecast_meter_rent_12m                     14606 non-null  float64\n",
      " 7   forecast_price_energy_off_peak              14606 non-null  float64\n",
      " 8   forecast_price_energy_peak                  14606 non-null  float64\n",
      " 9   forecast_price_pow_off_peak                 14606 non-null  float64\n",
      " 10  has_gas                                     14606 non-null  int64  \n",
      " 11  imp_cons                                    14606 non-null  float64\n",
      " 12  margin_gross_pow_ele                        14606 non-null  float64\n",
      " 13  margin_net_pow_ele                          14606 non-null  float64\n",
      " 14  nb_prod_act                                 14606 non-null  int64  \n",
      " 15  net_margin                                  14606 non-null  float64\n",
      " 16  pow_max                                     14606 non-null  float64\n",
      " 17  var_year_price_off_peak_var                 14606 non-null  float64\n",
      " 18  var_year_price_peak_var                     14606 non-null  float64\n",
      " 19  var_year_price_mid_peak_var                 14606 non-null  float64\n",
      " 20  var_year_price_off_peak_fix                 14606 non-null  float64\n",
      " 21  var_year_price_peak_fix                     14606 non-null  float64\n",
      " 22  var_year_price_mid_peak_fix                 14606 non-null  float64\n",
      " 23  var_year_price_off_peak                     14606 non-null  float64\n",
      " 24  var_year_price_peak                         14606 non-null  float64\n",
      " 25  var_year_price_mid_peak                     14606 non-null  float64\n",
      " 26  var_6m_price_off_peak_var                   14606 non-null  float64\n",
      " 27  var_6m_price_peak_var                       14606 non-null  float64\n",
      " 28  var_6m_price_mid_peak_var                   14606 non-null  float64\n",
      " 29  var_6m_price_off_peak_fix                   14606 non-null  float64\n",
      " 30  var_6m_price_peak_fix                       14606 non-null  float64\n",
      " 31  var_6m_price_mid_peak_fix                   14606 non-null  float64\n",
      " 32  var_6m_price_off_peak                       14606 non-null  float64\n",
      " 33  var_6m_price_peak                           14606 non-null  float64\n",
      " 34  var_6m_price_mid_peak                       14606 non-null  float64\n",
      " 35  churn                                       14606 non-null  int64  \n",
      " 36  offpeak_diff_dec_january_energy             14606 non-null  float64\n",
      " 37  offpeak_diff_dec_january_power              14606 non-null  float64\n",
      " 38  off_peak_peak_var_mean_diff                 14606 non-null  float64\n",
      " 39  peak_mid_peak_var_mean_diff                 14606 non-null  float64\n",
      " 40  off_peak_mid_peak_var_mean_diff             14606 non-null  float64\n",
      " 41  off_peak_peak_fix_mean_diff                 14606 non-null  float64\n",
      " 42  peak_mid_peak_fix_mean_diff                 14606 non-null  float64\n",
      " 43  off_peak_mid_peak_fix_mean_diff             14606 non-null  float64\n",
      " 44  off_peak_peak_var_max_monthly_diff          14606 non-null  float64\n",
      " 45  peak_mid_peak_var_max_monthly_diff          14606 non-null  float64\n",
      " 46  off_peak_mid_peak_var_max_monthly_diff      14606 non-null  float64\n",
      " 47  off_peak_peak_fix_max_monthly_diff          14606 non-null  float64\n",
      " 48  peak_mid_peak_fix_max_monthly_diff          14606 non-null  float64\n",
      " 49  off_peak_mid_peak_fix_max_monthly_diff      14606 non-null  float64\n",
      " 50  tenure                                      14606 non-null  int64  \n",
      " 51  months_activ                                14606 non-null  int64  \n",
      " 52  months_to_end                               14606 non-null  int64  \n",
      " 53  months_modif_prod                           14606 non-null  int64  \n",
      " 54  months_renewal                              14606 non-null  int64  \n",
      " 55  channel_MISSING                             14606 non-null  int64  \n",
      " 56  channel_ewpakwlliwisiwduibdlfmalxowmwpci    14606 non-null  int64  \n",
      " 57  channel_foosdfpfkusacimwkcsosbicdxkicaua    14606 non-null  int64  \n",
      " 58  channel_lmkebamcaaclubfxadlmueccxoimlema    14606 non-null  int64  \n",
      " 59  channel_usilxuppasemubllopkaafesmlibmsdf    14606 non-null  int64  \n",
      " 60  origin_up_kamkkxfxxuwbdslkwifmmcsiusiuosws  14606 non-null  int64  \n",
      " 61  origin_up_ldkssxwpmemidmecebumciepifcamkci  14606 non-null  int64  \n",
      " 62  origin_up_lxidpiddsbxsbosboudacockeimpuepw  14606 non-null  int64  \n",
      "dtypes: float64(46), int64(16), object(1)\n",
      "memory usage: 7.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2gjvbtCUSKV"
   },
   "source": [
    "---\n",
    "\n",
    "## 3. Modelling\n",
    "\n",
    "We now have a dataset containing features that we have engineered and we are ready to start training a predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cPHZWHC8USKV"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PitUvSFhUSKV"
   },
   "source": [
    "### Data sampling\n",
    "\n",
    "The first thing we want to do is split our dataset into training and test samples. The reason why we do this, is so that we can simulate a real life situation by generating predictions for our test sample, without showing the predictive model these data points. This gives us the ability to see how well our model is able to generalise to new data, which is critical.\n",
    "\n",
    "A typical % to dedicate to testing is between 20-30, for this example we will use a 75-25% split between train and test respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dstIVhBnUSKW",
    "outputId": "fdc82a65-36c0-4229-d729-161989dccda7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14606, 61)\n",
      "(14606,)\n",
      "churn\n",
      "0    13187\n",
      "1     1419\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Make a copy of our data\n",
    "train_df = df.copy()\n",
    "\n",
    "# Separate target variable from independent variables\n",
    "y = df['churn']\n",
    "X = df.drop(columns=['id', 'churn'])\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ifim4p1WUSKW",
    "outputId": "d689475d-555c-48d0-a0be-a0fbe812ab47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10954, 61)\n",
      "(10954,)\n",
      "(3652, 61)\n",
      "(3652,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### handling imbalance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22A_oe_PUSKX"
   },
   "source": [
    "### Model training\n",
    "\n",
    "## About random forest classifier\n",
    "\n",
    "Once again, we are using a `Random Forest` classifier in this example. A Random Forest sits within the category of `ensemble` algorithms because internally the `Forest` refers to a collection of `Decision Trees` which are tree-based learning algorithms. As the data scientist, you can control how large the forest is (that is, how many decision trees you want to include).\n",
    "\n",
    "The reason why an `ensemble` algorithm is powerful is because of the laws of averaging, weak learners and the central limit theorem. If we take a single decision tree and give it a sample of data and some parameters, it will learn patterns from the data. It may be overfit or it may be underfit, but that is now our only hope, that single algorithm. \n",
    "\n",
    "With `ensemble` methods, instead of banking on 1 single trained model, we can train 1000's of decision trees, all using different splits of the data and learning different patterns. It would be like asking 1000 people to all learn how to code. You would end up with 1000 people with different answers, methods and styles! The weak learner notion applies here too, it has been found that if you train your learners not to overfit, but to learn weak patterns within the data and you have a lot of these weak learners, together they come together to form a highly predictive pool of knowledge! This is a real life application of many brains are better than 1.\n",
    "\n",
    "Now instead of relying on 1 single decision tree for prediction, the random forest puts it to the overall views of the entire collection of decision trees. Some ensemble algorithms using a voting approach to decide which prediction is best, others using averaging. \n",
    "\n",
    "As we increase the number of learners, the idea is that the random forest's performance should converge to its best possible solution.\n",
    "\n",
    "Some additional advantages of the random forest classifier include:\n",
    "\n",
    "- The random forest uses a rule-based approach instead of a distance calculation and so features do not need to be scaled\n",
    "- It is able to handle non-linear parameters better than linear based models\n",
    "\n",
    "On the flip side, some disadvantages of the random forest classifier include:\n",
    "\n",
    "- The computational power needed to train a random forest on a large dataset is high, since we need to build a whole ensemble of estimators.\n",
    "- Training time can be longer due to the increased complexity and size of thee ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using randomizedSearchCV to increase model performance \n",
    "param_dist = {\n",
    "    'n_estimators': [200, 300, 400, 500],\n",
    "    'max_depth': [None, 15, 25],\n",
    "    'max_features': ['sqrt', 'log2', 0.3],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "rf = RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=25,   # random combos for speed\n",
    "    cv=5,\n",
    "    scoring='f1_macro',  # more robust for imbalance\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Best Params: {'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 25, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "search.fit(X_train_res, y_train_res)\n",
    "best_model = search.best_estimator_\n",
    "print(\"Best Params:\", search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "km_R7pYnUSKX"
   },
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test) # for classification report \n",
    "y_proba = best_model.predict_proba(X_test)[:, 1] # for probability based metrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwueFNNZUSKY"
   },
   "source": [
    "### Evaluation\n",
    "\n",
    "Now let's evaluate how well this trained model is able to predict the values of the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KRXNkqQYUSKY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      3286\n",
      "           1       0.58      0.09      0.16       366\n",
      "\n",
      "    accuracy                           0.90      3652\n",
      "   macro avg       0.74      0.54      0.55      3652\n",
      "weighted avg       0.87      0.90      0.87      3652\n",
      "\n",
      "ROC-AUC: 0.6522982914766737\n",
      "F1 (macro): 0.5540514609681639\n",
      "Log Loss: 0.33328866367492505\n"
     ]
    }
   ],
   "source": [
    "# Calculate performance metrics here!\n",
    "from sklearn.metrics import classification_report,roc_auc_score,f1_score,log_loss\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(\"F1 (macro):\", f1_score(y_test, y_pred, average='macro'))\n",
    "print(\"Log Loss:\", log_loss(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now lets try XGboost in place in random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier \n",
    "\n",
    "# Define the hyperparameter \n",
    "param_dist = {\n",
    "    'n_estimators': [200, 300, 400, 500],#Number of boosting rounds (trees)\n",
    "    'max_depth': [3, 5, 7, 10, 15],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2], #Step size shrinkage to prevent overfitting (Regularization)\n",
    "    'gamma': [0, 0.1, 0.5, 1], # Minimum loss reduction required to make a further partition\n",
    "    'min_child_weight': [1, 5, 10], # Minimum sum of instance weight (hessian) needed in a child\n",
    "    'subsample': [0.6, 0.8, 1.0], # Subsample ratio of the training instances\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0], # Subsample ratio of columns when constructing each tree\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "# Use 'scale_pos_weight' if you choose to skip SMOTE, but here we assume SMOTE is used.\n",
    "xgb_model = XGBClassifier(\n",
    "    random_state=42, \n",
    "    n_jobs=-1,\n",
    "    use_label_encoder=False, \n",
    "    eval_metric='logloss' \n",
    ")\n",
    "\n",
    "# Initialize RandomizedSearchCV with the XGBoost model\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=25,   # random combos for speed\n",
    "    cv=5,\n",
    "    scoring='f1_macro',  # more robust for imbalance\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training and fitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prath\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [15:52:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'subsample': 0.8, 'n_estimators': 200, 'min_child_weight': 1, 'max_depth': 15, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model (Cell 46)\n",
    "search.fit(X_train_res, y_train_res) \n",
    "best_model = search.best_estimator_\n",
    "print(\"Best Params:\", search.best_params_)\n",
    "\n",
    "# Prediction (Cell after 46)\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.95      3286\n",
      "           1       0.53      0.16      0.24       366\n",
      "\n",
      "    accuracy                           0.90      3652\n",
      "   macro avg       0.72      0.57      0.59      3652\n",
      "weighted avg       0.87      0.90      0.88      3652\n",
      "\n",
      "ROC-AUC: 0.6700857088692217\n",
      "F1 (macro): 0.5938988453768742\n",
      "Log Loss: 0.381408241435056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,roc_auc_score,f1_score,log_loss\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(\"F1 (macro):\", f1_score(y_test, y_pred, average='macro'))\n",
    "print(\"Log Loss:\", log_loss(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### why i choose these evaluation metrics\n",
    "\n",
    "1.simple accuracy is misleading because of class imbalance \n",
    "\n",
    "2.ROC-AUC gives more information about the ability of our model to seprate classes\n",
    "\n",
    "3.classification report provides parameters like precision and recall which are better options to understand performance of our model\n",
    "\n",
    "4.f1 macro treats both classes equally no matter if there is imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final thoughts\n",
    "1.altough the final evaluation of xgboost too didn't performed as expected but still better than random forest as can be seen in recall and f1(macro).\n",
    "\n",
    "2.more hyperparameter tuning is needed and i in future i can try other algorithms too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "interpreter": {
   "hash": "152bf6e7dc8ee53edb5af21dc1a8faeab7f134840808a94079ed98d91ece7e0c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
